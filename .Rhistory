#' @param graph The network graph
#' @param beliefs Belief array
#' @param types Type matrix
#' @param params List of simulation parameters
#' @param disclosure_type Type of disclosure ("selective" or "global")
#' @param round Current round number
#' @return List containing updated graph, beliefs, and outcomes
run_simulation_round <- function(graph,
beliefs,
types,
params,
disclosure_type,
round) {
N <- params$N
L <- params$L
delta <- params$delta
s <- params$s
model_version <- params$model_version
# Randomize agent order for this round
agent_order <- sample(1:N)
# Store actions for this round
round_actions <- rep("reveal nothing", N)
# Calculate shortest paths for utility calculations
distances <- distances(graph)
# Process each agent in the randomized order
for (idx in 1:N) {
i <- agent_order[idx]
# For dynamic networks: rewire connections
if (model_version == "dynamic") {
graph <- rewire_connections(graph, i, beliefs, types, L)
# Recalculate distances after rewiring
distances <- distances(graph)
}
# Determine target agents for disclosure
if (disclosure_type == "selective") {
# Random sample of s agents, excluding the current agent
other_agents <- setdiff(1:N, i)
target_agents <- sample(other_agents, min(params$s, N - 1))
} else {
# Global disclosure to all agents except self
target_agents <- setdiff(1:N, i)
}
# Decide best action
action_result <- decide_best_action(i, target_agents, distances, beliefs, types, L, delta)
best_action <- action_result$action
round_actions[i] <- best_action
# Update beliefs based on action
if (best_action != "reveal nothing") {
trait_to_reveal <- extract_trait_number(best_action)
if (!is.na(trait_to_reveal)) {
for (j in target_agents) {
beliefs[j, i, trait_to_reveal] <- types[i, trait_to_reveal]
}
}
}
}
# Calculate outcome measures for this round
perceived_similarity_matrix <- compute_similarity_outcomes(graph, beliefs, types, N, L)$similarity_matrices$perceived
revealed_perceived_similarity_matrix <- compute_similarity_outcomes(graph, beliefs, types, N, L)$similarity_matrices$perceived
# Store results
outcomes <- list(
similarity = compute_similarity_outcomes(graph, beliefs, types, N, L),
polarization = calculate_polarization_metrics(perceived_similarity_matrix),
network = calculate_network_metrics(graph),
utilities = calculate_all_utilities(distances, beliefs, types, N, L, delta),
actions = round_actions
)
# Add welfare metrics
outcomes$welfare <- calculate_welfare(outcomes$utilities)
return(list(
graph = graph,
beliefs = beliefs,
outcomes = outcomes,
round = round
))
}
#' Run a complete simulation
#'
#' @param params List of simulation parameters
#' @return List of simulation results
run_simulation <- function(params) {
# Extract parameters
N <- params$N
L <- params$L
T <- params$T
network_type <- params$network_type
init_type <- params$init_type
model_version <- params$model_version
disclosure_type <- params$disclosure_type
p <- params$p
k <- params$k
b <- params$b
delta <- params$delta
s <- params$s
# Initialize network
graph <- generate_network(network_type, N, p, k)
# Initialize agent type vectors
types <- initialize_types(N, L, init_type, b)
# Initialize belief matrices
beliefs <- initialize_beliefs(N, L, types)
# Initialize storage for simulation results
results <- list(
params = params,
rounds = list(),
disclosure_history = list()
)
# Run simulation for T rounds
for (t in 1:T) {
# Run a single round
round_result <- run_simulation_round(graph, beliefs, types, params, disclosure_type, t)
# Update graph and beliefs
graph <- round_result$graph
beliefs <- round_result$beliefs
# Store results
results$rounds[[t]] <- round_result$outcomes
results$disclosure_history[[t]] <- round_result$outcomes$actions
}
# Calculate overall disclosure metrics
results$disclosure_metrics <- calculate_disclosure_metrics(results$disclosure_history, N, T, L)
# Store final network state
results$final_network <- graph
results$final_beliefs <- beliefs
return(results)
}
#' Process simulation results for analysis and visualization
#'
#' @param results List of simulation results
#' @return List of processed data frames for analysis
process_simulation_results <- function(results) {
T <- length(results$rounds)
# Extract time series data
rounds_data <- data.frame(
round = 1:T,
perceived_neighbor_similarity = sapply(1:T, function(t)
results$rounds[[t]]$similarity$perceived_neighbor_similarity),
perceived_all_similarity = sapply(1:T, function(t)
results$rounds[[t]]$similarity$perceived_all_similarity),
perceived_similarity_gap = sapply(1:T, function(t)
results$rounds[[t]]$similarity$perceived_similarity_gap),
objective_neighbor_similarity = sapply(1:T, function(t)
results$rounds[[t]]$similarity$objective_neighbor_similarity),
objective_all_similarity = sapply(1:T, function(t)
results$rounds[[t]]$similarity$objective_all_similarity),
objective_similarity_gap = sapply(1:T, function(t)
results$rounds[[t]]$similarity$objective_similarity_gap),
revealed_neighbor_similarity = sapply(1:T, function(t)
results$rounds[[t]]$similarity$revealed_neighbor_similarity),
revealed_all_similarity = sapply(1:T, function(t)
results$rounds[[t]]$similarity$revealed_all_similarity),
revealed_similarity_gap = sapply(1:T, function(t)
results$rounds[[t]]$similarity$revealed_similarity_gap),
variance = sapply(1:T, function(t)
results$rounds[[t]]$polarization$variance),
bimodality = sapply(1:T, function(t)
results$rounds[[t]]$polarization$bimodality_index),
clustering = sapply(1:T, function(t)
results$rounds[[t]]$network$avg_clustering),
path_length = sapply(1:T, function(t)
results$rounds[[t]]$network$avg_path_length),
modularity = sapply(1:T, function(t)
results$rounds[[t]]$network$modularity),
mean_welfare = sapply(1:T, function(t)
results$rounds[[t]]$welfare$mean_welfare),
gini = sapply(1:T, function(t)
results$rounds[[t]]$welfare$gini_coefficient)
)
# Process disclosure data
# pull N×L matrix from disclosure_metrics
mat <- results$disclosure_metrics$agent_trait_counts
# Name columns "1","2",…,"L" so pivoted trait values are numeric strings
colnames(mat) <- seq_len(ncol(mat))
# pivot to long form: one row per (agent, trait)
agent_disclosure_df <- as.data.frame(mat, stringsAsFactors = FALSE) %>%
tibble::rownames_to_column("agent") %>%
tidyr::pivot_longer(cols = -agent,
names_to  = "trait",
values_to = "n_disclosed") %>%
dplyr::mutate(agent = as.integer(agent), trait = as.integer(trait))
# Process trait disclosure data
trait_disclosure_data <- data.frame(
trait = 1:results$params$L,
disclosure_rate = results$disclosure_metrics$trait_disclosure_rates
)
# Save disclosure metrics
results$params$disclosure_metrics <- results$disclosure_metrics
# Round all numeric columns to *two* decimals
rounds_data <- as.data.frame(lapply(rounds_data, function(x) {
if (is.numeric(x))
round(x, 2)
else
x
}))
# Return processed data
return(
list(
time_series = rounds_data,
agent_disclosures = agent_disclosure_df,
trait_disclosures = trait_disclosure_data,
params = results$params
)
)
}
###############################################################
# PART 7: VISUALIZATION FUNCTIONS
###############################################################
#' Create time series plots of key metrics
#'
#' @param processed_results Processed simulation results
#' @return List of ggplot objects
create_time_series_plots <- function(processed_results) {
df <- processed_results$time_series
# Similarity plot
expanded_similarity_plot <- ggplot(df, aes(x = round)) +
geom_line(aes(y = perceived_neighbor_similarity, color = "Perceived (Neighbor)"),
linewidth = 1) +
geom_line(
aes(y = perceived_all_similarity, color = "Perceived (All)"),
linewidth = 1,
linetype = "dashed"
) +
geom_line(aes(y = objective_neighbor_similarity, color = "Objective (Neighbor)"),
linewidth = 1) +
geom_line(
aes(y = objective_all_similarity, color = "Objective (All)"),
linewidth = 1,
linetype = "dashed"
) +
geom_line(aes(y = revealed_neighbor_similarity, color = "Revealed (Neighbor)"),
linewidth = 1) +
geom_line(
aes(y = revealed_all_similarity, color = "Revealed (All)"),
linewidth = 1,
linetype = "dashed"
) +
labs(
title = "Expanded Similarity Measures Over Time",
x = "Round",
y = "Similarity",
color = "Measure"
) +
theme_minimal() +
scale_color_brewer(palette = "Paired")
# Polarization plot
polarization_plot <- ggplot(df, aes(x = round)) +
geom_line(aes(y = variance, color = "Variance"), linewidth = 1) +
geom_line(aes(y = bimodality, color = "Bimodality"), linewidth = 1) +
labs(
title = "Polarization Measures Over Time",
x = "Round",
y = "Value",
color = "Measure"
) +
theme_minimal() +
scale_color_brewer(palette = "Set2")
# Network metrics plot
network_plot <- ggplot(df, aes(x = round)) +
geom_line(aes(y = clustering, color = "Clustering"), linewidth = 1) +
geom_line(aes(y = modularity, color = "Modularity"), linewidth = 1) +
labs(
title = "Network Metrics Over Time",
x = "Round",
y = "Value",
color = "Measure"
) +
theme_minimal() +
scale_color_brewer(palette = "Set3")
# Welfare plot
welfare_plot <- ggplot(df, aes(x = round)) +
geom_line(aes(y = mean_welfare, color = "Total Welfare"), linewidth = 1) +
geom_line(aes(y = gini * 100, color = "Gini Coefficient"), linewidth = 1) +
labs(
title = "Welfare Measures Over Time",
x = "Round",
y = "Value",
color = "Measure"
) +
theme_minimal() +
scale_color_brewer(palette = "Dark2") +
scale_y_continuous(sec.axis = sec_axis( ~ . / 100, name = "Gini Coefficient"))
return(
list(
expanded_similarity = expanded_similarity_plot,
polarization = polarization_plot,
network = network_plot,
welfare = welfare_plot
)
)
}
#' Visualize the network with node colors based on similarity
#'
#' @param graph The network graph
#' @param perceived_similarity_matrix Matrix of similarity values
#' @return ggplot object of the network
visualize_network <- function(graph, perceived_similarity_matrix) {
# Calculate average similarity for each node
n <- vcount(graph)
avg_similarities <- rowMeans(perceived_similarity_matrix, na.rm = TRUE)
# Normalize for color mapping
node_colors <- (avg_similarities - min(avg_similarities)) /
(max(avg_similarities) - min(avg_similarities))
# Get layout
layout <- layout_with_fr(graph)
# Convert to data frames for ggplot
nodes <- data.frame(
id = 1:n,
x = layout[, 1],
y = layout[, 2],
similarity = avg_similarities
)
edges <- data.frame(from = ends(graph, E(graph))[, 1], to = ends(graph, E(graph))[, 2])
edges_for_plot <- data.frame(
x = layout[edges$from, 1],
y = layout[edges$from, 2],
xend = layout[edges$to, 1],
yend = layout[edges$to, 2]
)
# Create network plot
plot <- ggplot() +
geom_segment(data = edges_for_plot,
aes(
x = x,
y = y,
xend = xend,
yend = yend
),
alpha = 0.5) +
geom_point(
data = nodes,
aes(x = x, y = y, fill = similarity),
shape = 21,
size = 5,
color = "black"
) +
scale_fill_gradient(low = "blue", high = "red") +
labs(title = "Network Visualization", fill = "Avg. Similarity") +
theme_void() +
theme(legend.position = "right")
return(plot)
}
###############################################################
# PART 8: PARAMETER SWEEP FUNCTIONS
###############################################################
#' Run multiple simulations with different parameter combinations
#'
#' @param base_params Base parameter list
#' @param param_grid List of parameter grids to sweep
#' @param num_runs Number of runs per parameter combination
#' @return Data frame of aggregated results
# Adds an optional progress callback to report completion % to the UI
run_parameter_sweep <- function(base_params, param_grid, num_runs, progress_callback = NULL) {
# Dbug
future::plan("sequential")
set.seed(42)
# 1. Expand parameter grid
grid <- expand.grid(param_grid, stringsAsFactors = FALSE)
n_grid <- nrow(grid)
# 2. Replicate each grid row num_runs times and assign run IDs
combos <- grid[rep(seq_len(n_grid), each = num_runs), , drop = FALSE]
combos$run_id <- rep(seq_len(num_runs), times = n_grid)
total_iters <- nrow(combos)
results_list <- vector("list", total_iters)
# 3. Iterate through each combination, run simulation, extract final metrics
for (i in seq_len(total_iters)) {
row <- combos[i, ]
# Merge base params with this combination
# Only use the names in param_grid (e.g. N, L, T, network_type, model_version, disclosure_type)
params <- base_params
for (name in names(param_grid)) {
params[[name]] <- row[[name]]
}
cat("▶ combo", i, "params:", paste(names(params), params, sep="=", collapse=", "), "\n")
if (is.null(params$T) || params$T < 1) stop("Invalid T: must be ≥ 1")
# Run simulation and process results
sim <- tryCatch({
run_simulation(params)
}, error = function(e) {
cat("Simulation failed for params:\n")
print(params)
cat("Error message:\n")
print(e$message)
stop("Aborting sweep due to simulation error.")
})
out  <- process_simulation_results(sim)$time_series
if (nrow(out) == 0) stop("❌ Time series output is empty!")
last <- out[nrow(out), , drop = FALSE]
print(paste("Column names in `last`:", toString(names(last))))
# Collect final metrics for this run
results_list[[i]] <- tibble(
network_type   = params$network_type,
model_version  = params$model_version,
disclosure_type= params$disclosure_type,
delta          = params$delta,
b              = params$b,
run_id         = row$run_id,
final_perceived_neighbor_similarity = last$perceived_neighbor_similarity[[1]],
final_perceived_all_similarity      = last$perceived_all_similarity[[1]],
final_perceived_similarity_gap      = last$perceived_similarity_gap[[1]],
final_objective_neighbor_similarity = last$objective_neighbor_similarity[[1]],
final_objective_all_similarity      = last$objective_all_similarity[[1]],
final_objective_similarity_gap      = last$objective_similarity_gap[[1]],
final_revealed_neighbor_similarity  = last$revealed_neighbor_similarity[[1]],
final_revealed_all_similarity       = last$revealed_all_similarity[[1]],
final_revealed_similarity_gap       = last$revealed_similarity_gap[[1]],
final_variance                      = last$variance[[1]],
final_bimodality                    = last$bimodality[[1]],
final_clustering                    = last$clustering[[1]],
final_modularity                    = last$modularity[[1]],
final_mean_welfare                  = last$mean_welfare[[1]],
final_gini                          = last$gini[[1]]
)
# Report progress if callback provided
if (!is.null(progress_callback)) {
pct <- floor((i / total_iters) * 100)
progress_callback(pct)
}
}
# 4. Combine and return results
results <- dplyr::bind_rows(results_list)
return(results)
}
#' Process sweep results into a flat data frame
#'
#' @param results List of simulation results
#' @param param_combinations Data frame of parameter combinations
#' @return Data frame with aggregated metrics
process_sweep_results <- function(results, param_combinations) {
num_combinations <- nrow(param_combinations)
num_runs <- length(results[[1]]$runs)
# Initialize data frame for storing results
result_rows <- list()
for (i in 1:num_combinations) {
for (run in 1:num_runs) {
# Get final round metrics
final_round <- results[[i]]$runs[[run]]$time_series[nrow(results[[i]]$runs[[run]]$time_series), ]
# Create row with parameters and final metrics
row <- c(
as.list(param_combinations[i, ]),
run = run,
final_perceived_neighbor_similarity = final_round$perceived_neighbor_similarity,
final_perceived_all_similarity = final_round$perceived_all_similarity,
final_perceived_similarity_gap = final_round$perceived_similarity_gap,
final_objective_neighbor_similarity = final_round$objective_neighbor_similarity,
final_objective_all_similarity = final_round$objective_all_similarity,
final_objective_similarity_gap = final_round$objective_similarity_gap,
final_revealed_neighbor_similarity = final_round$revealed_neighbor_similarity,
final_revealed_all_similarity = final_round$revealed_all_similarity,
final_revealed_similarity_gap = final_round$revealed_similarity_gap,
final_variance = final_round$variance,
final_bimodality = final_round$bimodality,
final_clustering = final_round$clustering,
final_path_length = final_round$path_length,
final_modularity = final_round$modularity,
final_welfare = final_round$mean_welfare,
final_gini = final_round$gini,
# disclosure_rate = results[[i]]$runs[[run]]$params$disclosure_metrics$disclosure_rate
)
result_rows[[length(result_rows) + 1]] <- row
}
}
# Convert list to data frame
results_df <- do.call(rbind.data.frame, result_rows)
# Round all numeric columns to *two* decimals
results_df <- as.data.frame(lapply(results_df, function(x) {
if (is.numeric(x))
round(x, 2)
else
x
}))
return(results_df)
}
###############################################################
# PART 9: SAMPLE USAGE
###############################################################
# Example parameter set
example_params <- list(
N = 50,
# Number of agents
L = 5,
# Length of type vector
T = 20,
# Number of rounds
network_type = "WS",
# Network type: "ER", "WS", or "BA"
p = 0.1,
# Probability parameter for network generation
k = 4,
# Degree parameter for network generation
init_type = "random",
# Type vector initialization: "random" or "polarized"
b = 0.7,
# Bias parameter for polarized initialization
delta = 0.5,
# Influence decay factor
s = 10,
# Size of target subset for selective disclosure
model_version = "static",
# Network version: "static" or "dynamic"
disclosure_type = "selective" # Disclosure type: "selective" or "global"
)
###############################################################
# END OF CODE
###############################################################
shiny::runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Disclosure-Control-Network-Model')
runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Disclosure-Control-Network-Model')
runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Disclosure-Control-Network-Model')
runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Disclosure-Control-Network-Model')
runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Disclosure-Control-Network-Model')
shiny::runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Disclosure-Control-Network-Model')
shiny::runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Minimal-Grant-Funding-Model')
shiny::runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Grant-Funding-and-Scientific-Output-Model')
runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Grant-Funding-and-Scientific-Output-Model')
runApp('Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/Grant-Funding-and-Scientific-Output-Model')
